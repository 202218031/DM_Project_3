{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOtJgehxJMDmn+ld0ZKEXWv"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gB0vJrkAu0sw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Scraping Data**"
      ],
      "metadata": {
        "id": "lpCZZsvfUFYl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://www.espncricinfo.com/records/tournament/bowling-most-wickets-career/icc-cricket-world-cup-2023-24-15338'\n",
        "all_tables = pd.read_html(url)\n",
        "current_wc_df = all_tables[0]\n",
        "print(current_wc_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1EIzxmtrKVJ",
        "outputId": "db3226cf-8e40-44bd-c383-617fb2a940d4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       Player       Span  Mat  Inns  Balls  Overs Mdns  Runs  \\\n",
            "0               A Zampa (AUS)  2023-2023    9     9    474   79.0    1   416   \n",
            "1           D Madushanka (SL)  2023-2023    9     9    470   78.2    4   525   \n",
            "2              G Coetzee (SA)  2023-2023    7     7    327   54.3    1   349   \n",
            "3   Shaheen Shah Afridi (PAK)  2023-2023    9     9    486   81.0    3   481   \n",
            "4             JJ Bumrah (IND)  2023-2023    9     9    437   72.5    6   266   \n",
            "..                        ...        ...  ...   ...    ...    ...  ...   ...   \n",
            "77              V Kohli (IND)  2023-2023    9     2     21    3.3    -    15   \n",
            "78             R Ashwin (IND)  2023-2023    1     1     60   10.0    1    34   \n",
            "79        AL Phehlukwayo (SA)  2023-2023    1     1     42    7.0    -    36   \n",
            "80       Saqib Zulfiqar (NED)  2023-2023    2     2     30    5.0    -    40   \n",
            "81              JE Root (ENG)  2023-2023    9     2     61   10.1    -    67   \n",
            "\n",
            "    Wkts   BBI    Ave  Econ     SR  4  5  \n",
            "0     22   4/8  18.90  5.26  21.54  3  -  \n",
            "1     21  5/80  25.00  6.70  22.38  1  1  \n",
            "2     18  4/44  19.38  6.40  18.16  1  -  \n",
            "3     18  5/54  26.72  5.93  27.00  -  1  \n",
            "4     17  4/39  15.64  3.65  25.70  1  -  \n",
            "..   ...   ...    ...   ...    ... .. ..  \n",
            "77     1  1/13  15.00  4.28  21.00  -  -  \n",
            "78     1  1/34  34.00  3.40  60.00  -  -  \n",
            "79     1  1/36  36.00  5.14  42.00  -  -  \n",
            "80     1  1/25  40.00  8.00  30.00  -  -  \n",
            "81     1  1/19  67.00  6.59  61.00  -  -  \n",
            "\n",
            "[82 rows x 15 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://www.espncricinfo.com/records/trophy/bowling-most-wickets-career/world-cup-12'\n",
        "all_tables = pd.read_html(url)\n",
        "past_wc_df = all_tables[0]\n",
        "print(past_wc_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHEJT-wSsUrH",
        "outputId": "8f786a47-12b2-4ef6-ce23-06e8497eaa45"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                Player       Span  Mat  Inns  Balls  Overs  Mdns  Runs  Wkts  \\\n",
            "0     GD McGrath (AUS)  1996-2007   39    39   1955  325.5    42  1292    71   \n",
            "1   M Muralidaran (SL)  1996-2011   40    39   2061  343.3    15  1335    68   \n",
            "2       MA Starc (AUS)  2015-2023   26    26   1339  223.1     9  1165    59   \n",
            "3      SL Malinga (SL)  2007-2019   29    28   1394  232.2    11  1281    56   \n",
            "4    Wasim Akram (PAK)  1987-2003   38    36   1947  324.3    16  1311    55   \n",
            "..                 ...        ...  ...   ...    ...    ...   ...   ...   ...   \n",
            "95   Aaqib Javed (PAK)  1992-1996   15    15    746  124.2    13   517    18   \n",
            "96   MO Odumbe (KENYA)  1996-2003   19    16    701  116.5     9   567    18   \n",
            "97      GR Larsen (NZ)  1992-1999   19    19   1020  170.0    12   599    18   \n",
            "98      CL Hooper (WI)  1987-2003   20    17    924  154.0     3   659    18   \n",
            "99      CL Cairns (NZ)  1992-2003   28    23    880  146.4     9   755    18   \n",
            "\n",
            "     BBI    Ave  Econ     SR  4  5  \n",
            "0   7/15  18.19  3.96  27.53  -  2  \n",
            "1   4/19  19.63  3.88  30.30  4  -  \n",
            "2   6/28  19.74  5.22  22.69  3  3  \n",
            "3   6/38  22.87  5.51  24.89  2  1  \n",
            "4   5/28  23.83  4.04  35.40  2  1  \n",
            "..   ...    ...   ...    ... .. ..  \n",
            "95  3/21  28.72  4.15  41.44  -  -  \n",
            "96  4/38  31.50  4.85  38.94  1  -  \n",
            "97  3/16  33.27  3.52  56.66  -  -  \n",
            "98  3/42  36.61  4.27  51.33  -  -  \n",
            "99  3/19  41.94  5.14  48.88  -  -  \n",
            "\n",
            "[100 rows x 15 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.DataFrame(current_wc_df)\n",
        "df2 = pd.DataFrame(past_wc_df)"
      ],
      "metadata": {
        "id": "UbQPTX_guBD2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frames=[df1,df2]\n",
        "wkts_df = pd.concat(frames)"
      ],
      "metadata": {
        "id": "AmsVLOHtnso_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wkts_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "w5qp_mHeujV0",
        "outputId": "2116f33b-4368-4478-b242-e8724959bc3f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       Player       Span  Mat  Inns  Balls  Overs Mdns  Runs  \\\n",
              "0               A Zampa (AUS)  2023-2023    9     9    474   79.0    1   416   \n",
              "1           D Madushanka (SL)  2023-2023    9     9    470   78.2    4   525   \n",
              "2              G Coetzee (SA)  2023-2023    7     7    327   54.3    1   349   \n",
              "3   Shaheen Shah Afridi (PAK)  2023-2023    9     9    486   81.0    3   481   \n",
              "4             JJ Bumrah (IND)  2023-2023    9     9    437   72.5    6   266   \n",
              "..                        ...        ...  ...   ...    ...    ...  ...   ...   \n",
              "95          Aaqib Javed (PAK)  1992-1996   15    15    746  124.2   13   517   \n",
              "96          MO Odumbe (KENYA)  1996-2003   19    16    701  116.5    9   567   \n",
              "97             GR Larsen (NZ)  1992-1999   19    19   1020  170.0   12   599   \n",
              "98             CL Hooper (WI)  1987-2003   20    17    924  154.0    3   659   \n",
              "99             CL Cairns (NZ)  1992-2003   28    23    880  146.4    9   755   \n",
              "\n",
              "    Wkts   BBI    Ave  Econ     SR  4  5  \n",
              "0     22   4/8  18.90  5.26  21.54  3  -  \n",
              "1     21  5/80  25.00  6.70  22.38  1  1  \n",
              "2     18  4/44  19.38  6.40  18.16  1  -  \n",
              "3     18  5/54  26.72  5.93  27.00  -  1  \n",
              "4     17  4/39  15.64  3.65  25.70  1  -  \n",
              "..   ...   ...    ...   ...    ... .. ..  \n",
              "95    18  3/21  28.72  4.15  41.44  -  -  \n",
              "96    18  4/38  31.50  4.85  38.94  1  -  \n",
              "97    18  3/16  33.27  3.52  56.66  -  -  \n",
              "98    18  3/42  36.61  4.27  51.33  -  -  \n",
              "99    18  3/19  41.94  5.14  48.88  -  -  \n",
              "\n",
              "[182 rows x 15 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-45d4bb44-2391-47ff-bf14-ee4687896ea1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Player</th>\n",
              "      <th>Span</th>\n",
              "      <th>Mat</th>\n",
              "      <th>Inns</th>\n",
              "      <th>Balls</th>\n",
              "      <th>Overs</th>\n",
              "      <th>Mdns</th>\n",
              "      <th>Runs</th>\n",
              "      <th>Wkts</th>\n",
              "      <th>BBI</th>\n",
              "      <th>Ave</th>\n",
              "      <th>Econ</th>\n",
              "      <th>SR</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A Zampa (AUS)</td>\n",
              "      <td>2023-2023</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>474</td>\n",
              "      <td>79.0</td>\n",
              "      <td>1</td>\n",
              "      <td>416</td>\n",
              "      <td>22</td>\n",
              "      <td>4/8</td>\n",
              "      <td>18.90</td>\n",
              "      <td>5.26</td>\n",
              "      <td>21.54</td>\n",
              "      <td>3</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>D Madushanka (SL)</td>\n",
              "      <td>2023-2023</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>470</td>\n",
              "      <td>78.2</td>\n",
              "      <td>4</td>\n",
              "      <td>525</td>\n",
              "      <td>21</td>\n",
              "      <td>5/80</td>\n",
              "      <td>25.00</td>\n",
              "      <td>6.70</td>\n",
              "      <td>22.38</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>G Coetzee (SA)</td>\n",
              "      <td>2023-2023</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>327</td>\n",
              "      <td>54.3</td>\n",
              "      <td>1</td>\n",
              "      <td>349</td>\n",
              "      <td>18</td>\n",
              "      <td>4/44</td>\n",
              "      <td>19.38</td>\n",
              "      <td>6.40</td>\n",
              "      <td>18.16</td>\n",
              "      <td>1</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Shaheen Shah Afridi (PAK)</td>\n",
              "      <td>2023-2023</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>486</td>\n",
              "      <td>81.0</td>\n",
              "      <td>3</td>\n",
              "      <td>481</td>\n",
              "      <td>18</td>\n",
              "      <td>5/54</td>\n",
              "      <td>26.72</td>\n",
              "      <td>5.93</td>\n",
              "      <td>27.00</td>\n",
              "      <td>-</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>JJ Bumrah (IND)</td>\n",
              "      <td>2023-2023</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>437</td>\n",
              "      <td>72.5</td>\n",
              "      <td>6</td>\n",
              "      <td>266</td>\n",
              "      <td>17</td>\n",
              "      <td>4/39</td>\n",
              "      <td>15.64</td>\n",
              "      <td>3.65</td>\n",
              "      <td>25.70</td>\n",
              "      <td>1</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>Aaqib Javed (PAK)</td>\n",
              "      <td>1992-1996</td>\n",
              "      <td>15</td>\n",
              "      <td>15</td>\n",
              "      <td>746</td>\n",
              "      <td>124.2</td>\n",
              "      <td>13</td>\n",
              "      <td>517</td>\n",
              "      <td>18</td>\n",
              "      <td>3/21</td>\n",
              "      <td>28.72</td>\n",
              "      <td>4.15</td>\n",
              "      <td>41.44</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>MO Odumbe (KENYA)</td>\n",
              "      <td>1996-2003</td>\n",
              "      <td>19</td>\n",
              "      <td>16</td>\n",
              "      <td>701</td>\n",
              "      <td>116.5</td>\n",
              "      <td>9</td>\n",
              "      <td>567</td>\n",
              "      <td>18</td>\n",
              "      <td>4/38</td>\n",
              "      <td>31.50</td>\n",
              "      <td>4.85</td>\n",
              "      <td>38.94</td>\n",
              "      <td>1</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>GR Larsen (NZ)</td>\n",
              "      <td>1992-1999</td>\n",
              "      <td>19</td>\n",
              "      <td>19</td>\n",
              "      <td>1020</td>\n",
              "      <td>170.0</td>\n",
              "      <td>12</td>\n",
              "      <td>599</td>\n",
              "      <td>18</td>\n",
              "      <td>3/16</td>\n",
              "      <td>33.27</td>\n",
              "      <td>3.52</td>\n",
              "      <td>56.66</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>CL Hooper (WI)</td>\n",
              "      <td>1987-2003</td>\n",
              "      <td>20</td>\n",
              "      <td>17</td>\n",
              "      <td>924</td>\n",
              "      <td>154.0</td>\n",
              "      <td>3</td>\n",
              "      <td>659</td>\n",
              "      <td>18</td>\n",
              "      <td>3/42</td>\n",
              "      <td>36.61</td>\n",
              "      <td>4.27</td>\n",
              "      <td>51.33</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>CL Cairns (NZ)</td>\n",
              "      <td>1992-2003</td>\n",
              "      <td>28</td>\n",
              "      <td>23</td>\n",
              "      <td>880</td>\n",
              "      <td>146.4</td>\n",
              "      <td>9</td>\n",
              "      <td>755</td>\n",
              "      <td>18</td>\n",
              "      <td>3/19</td>\n",
              "      <td>41.94</td>\n",
              "      <td>5.14</td>\n",
              "      <td>48.88</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>182 rows × 15 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-45d4bb44-2391-47ff-bf14-ee4687896ea1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-45d4bb44-2391-47ff-bf14-ee4687896ea1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-45d4bb44-2391-47ff-bf14-ee4687896ea1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6f70f566-50e8-4cb5-bf0a-bf4992696f33\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6f70f566-50e8-4cb5-bf0a-bf4992696f33')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6f70f566-50e8-4cb5-bf0a-bf4992696f33 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wkts_df.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-vbntmWxZE-",
        "outputId": "be6b6c2d-fb68-4954-df35-ad98d6085c17"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Player    0\n",
              "Span      0\n",
              "Mat       0\n",
              "Inns      0\n",
              "Balls     0\n",
              "Overs     0\n",
              "Mdns      0\n",
              "Runs      0\n",
              "Wkts      0\n",
              "BBI       0\n",
              "Ave       0\n",
              "Econ      0\n",
              "SR        0\n",
              "4         0\n",
              "5         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wkts_df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYkd1Gsxxlv4",
        "outputId": "c033c16e-2f8b-4f2b-8c1e-a5d86666a7a8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Player     object\n",
              "Span       object\n",
              "Mat         int64\n",
              "Inns        int64\n",
              "Balls       int64\n",
              "Overs     float64\n",
              "Mdns       object\n",
              "Runs        int64\n",
              "Wkts        int64\n",
              "BBI        object\n",
              "Ave       float64\n",
              "Econ      float64\n",
              "SR        float64\n",
              "4          object\n",
              "5          object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wkts_df = wkts_df.replace('-', '0')\n",
        "\n",
        "columns_to_clean = ['Mdns', 'BBI', '4', '5']\n",
        "\n",
        "for col in columns_to_clean:\n",
        "    wkts_df[col] = wkts_df[col].astype(str).str.replace(r'[*+]', '', regex=True)\n",
        "    wkts_df[col] = pd.to_numeric(wkts_df[col], errors='coerce')\n",
        "\n",
        "print(wkts_df.isna().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Z0dozvb5r0K",
        "outputId": "29897eef-6679-43fc-d974-fc2bced33b4e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Player      0\n",
            "Span        0\n",
            "Mat         0\n",
            "Inns        0\n",
            "Balls       0\n",
            "Overs       0\n",
            "Mdns        0\n",
            "Runs        0\n",
            "Wkts        0\n",
            "BBI       182\n",
            "Ave         0\n",
            "Econ        0\n",
            "SR          0\n",
            "4           0\n",
            "5           0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wkts_df = wkts_df.rename(columns={'4': 'Four_wickets', '5': 'Five_wickets'})"
      ],
      "metadata": {
        "id": "DSHSyJzHfga3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = ['Inns','Overs','Mdns','Econ','Four_wickets','Five_wickets']\n",
        "\n",
        "X = wkts_df[features]\n",
        "y = wkts_df['Wkts']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "fjlIj-GFhoL2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Linear Regression**"
      ],
      "metadata": {
        "id": "aOkFtwdfUSzX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "xFl2SRPVwiux",
        "outputId": "e934484f-ddc7-4bbd-8860-baffa17ef224"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "player_2023 = pd.DataFrame({\n",
        "    'Inns' : [9, 9, 7, 9, 9],\n",
        "    'Overs': [79.0, 78.2, 54.3, 81.0, 72.5],\n",
        "    'Mdns': [1, 4, 1, 3, 6],\n",
        "    'Econ': [5.26, 6.70, 6.40, 5.93, 3.65],\n",
        "    'Four_wickets': [3, 1, 1, 0, 1],\n",
        "    'Five_wickets': [0, 1, 0, 1, 0],\n",
        "})\n",
        "\n",
        "predicted_wkts_2023 = lr_model.predict(player_2023)\n",
        "player_2023['Predicted_wkts_2023'] = np.ceil(predicted_wkts_2023)\n",
        "print(player_2023)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AenQo5-e0QkG",
        "outputId": "795bdd06-cfda-4d97-c21c-219e94bee7da"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Inns  Overs  Mdns  Econ  Four_wickets  Five_wickets  Predicted_wkts_2023\n",
            "0     9   79.0     1  5.26             3             0                 23.0\n",
            "1     9   78.2     4  6.70             1             1                 20.0\n",
            "2     7   54.3     1  6.40             1             0                 13.0\n",
            "3     9   81.0     3  5.93             0             1                 17.0\n",
            "4     9   72.5     6  3.65             1             0                 15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(lr_model, open('LR_model_wkts.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "jveXp1Jmqeu3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ANN**"
      ],
      "metadata": {
        "id": "YF1ml_fMUWJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "metadata": {
        "id": "Zjtd7svhhwDf"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(units=64, activation='relu', input_shape=(len(features),)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dense(units=128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dense(units=1, activation='linear'))\n",
        "\n",
        "adam_custom = Adam(learning_rate=0.001)\n",
        "\n",
        "model.compile(optimizer=adam_custom, loss='mean_squared_error')\n",
        "\n",
        "model.fit(X_train, y_train, batch_size=64, epochs=200, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PDQfI7tQe_i",
        "outputId": "5c7dc571-819b-49ae-a361-67055b104b5c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "3/3 [==============================] - 1s 85ms/step - loss: 503.8941 - val_loss: 565.1475\n",
            "Epoch 2/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 461.1218 - val_loss: 558.6785\n",
            "Epoch 3/200\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 435.9830 - val_loss: 552.0790\n",
            "Epoch 4/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 420.0801 - val_loss: 545.6451\n",
            "Epoch 5/200\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 408.4108 - val_loss: 539.8258\n",
            "Epoch 6/200\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 400.3105 - val_loss: 535.0553\n",
            "Epoch 7/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 393.4070 - val_loss: 530.5830\n",
            "Epoch 8/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 389.4389 - val_loss: 525.8539\n",
            "Epoch 9/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 383.9359 - val_loss: 521.0413\n",
            "Epoch 10/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 376.1830 - val_loss: 516.4095\n",
            "Epoch 11/200\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 375.1184 - val_loss: 511.8757\n",
            "Epoch 12/200\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 370.7280 - val_loss: 507.4202\n",
            "Epoch 13/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 367.0721 - val_loss: 502.0942\n",
            "Epoch 14/200\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 361.9441 - val_loss: 497.1944\n",
            "Epoch 15/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 362.1045 - val_loss: 492.6415\n",
            "Epoch 16/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 354.2776 - val_loss: 488.0817\n",
            "Epoch 17/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 353.1687 - val_loss: 483.8359\n",
            "Epoch 18/200\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 347.5272 - val_loss: 480.1753\n",
            "Epoch 19/200\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 347.8737 - val_loss: 476.7677\n",
            "Epoch 20/200\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 344.8513 - val_loss: 472.8649\n",
            "Epoch 21/200\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 344.1654 - val_loss: 468.9339\n",
            "Epoch 22/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 339.6568 - val_loss: 466.3477\n",
            "Epoch 23/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 338.3123 - val_loss: 463.5430\n",
            "Epoch 24/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 337.7189 - val_loss: 460.7508\n",
            "Epoch 25/200\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 330.9379 - val_loss: 457.4751\n",
            "Epoch 26/200\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 335.1077 - val_loss: 454.0697\n",
            "Epoch 27/200\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 324.3012 - val_loss: 450.4394\n",
            "Epoch 28/200\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 324.6265 - val_loss: 447.0673\n",
            "Epoch 29/200\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 323.7335 - val_loss: 443.9204\n",
            "Epoch 30/200\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 319.7437 - val_loss: 440.4564\n",
            "Epoch 31/200\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 315.3230 - val_loss: 436.7961\n",
            "Epoch 32/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 316.8638 - val_loss: 433.1673\n",
            "Epoch 33/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 310.5202 - val_loss: 430.1957\n",
            "Epoch 34/200\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 311.2648 - val_loss: 427.7153\n",
            "Epoch 35/200\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 311.8167 - val_loss: 426.8638\n",
            "Epoch 36/200\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 304.4444 - val_loss: 426.3050\n",
            "Epoch 37/200\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 309.1193 - val_loss: 424.1036\n",
            "Epoch 38/200\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 300.1071 - val_loss: 419.9484\n",
            "Epoch 39/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 296.2683 - val_loss: 415.0663\n",
            "Epoch 40/200\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 300.0269 - val_loss: 409.7790\n",
            "Epoch 41/200\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 299.7022 - val_loss: 405.5203\n",
            "Epoch 42/200\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 288.0651 - val_loss: 400.5060\n",
            "Epoch 43/200\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 285.4220 - val_loss: 396.3481\n",
            "Epoch 44/200\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 285.2820 - val_loss: 394.2766\n",
            "Epoch 45/200\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 280.8317 - val_loss: 392.4876\n",
            "Epoch 46/200\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 279.4247 - val_loss: 387.8717\n",
            "Epoch 47/200\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 276.5621 - val_loss: 383.2144\n",
            "Epoch 48/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 273.7283 - val_loss: 379.1384\n",
            "Epoch 49/200\n",
            "3/3 [==============================] - 0s 62ms/step - loss: 271.5215 - val_loss: 376.0561\n",
            "Epoch 50/200\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 271.9661 - val_loss: 375.2159\n",
            "Epoch 51/200\n",
            "3/3 [==============================] - 0s 58ms/step - loss: 268.5769 - val_loss: 375.1142\n",
            "Epoch 52/200\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 267.0976 - val_loss: 371.9090\n",
            "Epoch 53/200\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 261.4134 - val_loss: 369.7761\n",
            "Epoch 54/200\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 259.6579 - val_loss: 368.8604\n",
            "Epoch 55/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 253.0626 - val_loss: 366.8893\n",
            "Epoch 56/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 252.8470 - val_loss: 363.9588\n",
            "Epoch 57/200\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 247.0531 - val_loss: 360.6381\n",
            "Epoch 58/200\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 254.4872 - val_loss: 356.3108\n",
            "Epoch 59/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 244.5318 - val_loss: 349.5491\n",
            "Epoch 60/200\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 242.0106 - val_loss: 343.2368\n",
            "Epoch 61/200\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 234.8386 - val_loss: 337.0479\n",
            "Epoch 62/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 235.9926 - val_loss: 333.4825\n",
            "Epoch 63/200\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 232.3751 - val_loss: 332.3495\n",
            "Epoch 64/200\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 230.9449 - val_loss: 331.1116\n",
            "Epoch 65/200\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 225.8923 - val_loss: 327.3141\n",
            "Epoch 66/200\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 223.8251 - val_loss: 323.5195\n",
            "Epoch 67/200\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 218.1763 - val_loss: 318.0408\n",
            "Epoch 68/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 212.5177 - val_loss: 312.2380\n",
            "Epoch 69/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 211.4808 - val_loss: 304.4975\n",
            "Epoch 70/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 205.6991 - val_loss: 301.3252\n",
            "Epoch 71/200\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 204.8889 - val_loss: 300.0878\n",
            "Epoch 72/200\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 201.8130 - val_loss: 297.0789\n",
            "Epoch 73/200\n",
            "3/3 [==============================] - 0s 64ms/step - loss: 197.4877 - val_loss: 296.1748\n",
            "Epoch 74/200\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 193.5638 - val_loss: 295.1598\n",
            "Epoch 75/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 190.6684 - val_loss: 292.3493\n",
            "Epoch 76/200\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 189.6122 - val_loss: 288.3476\n",
            "Epoch 77/200\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 184.3921 - val_loss: 283.0476\n",
            "Epoch 78/200\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 187.8781 - val_loss: 271.7554\n",
            "Epoch 79/200\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 178.9277 - val_loss: 265.8246\n",
            "Epoch 80/200\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 175.4320 - val_loss: 260.3931\n",
            "Epoch 81/200\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 170.5483 - val_loss: 256.4150\n",
            "Epoch 82/200\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 170.2719 - val_loss: 254.6748\n",
            "Epoch 83/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 166.4825 - val_loss: 250.2687\n",
            "Epoch 84/200\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 163.0819 - val_loss: 245.5317\n",
            "Epoch 85/200\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 160.0495 - val_loss: 243.1789\n",
            "Epoch 86/200\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 170.8004 - val_loss: 238.5272\n",
            "Epoch 87/200\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 157.4867 - val_loss: 230.5894\n",
            "Epoch 88/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 147.7167 - val_loss: 232.6663\n",
            "Epoch 89/200\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 143.3848 - val_loss: 232.2174\n",
            "Epoch 90/200\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 146.6532 - val_loss: 229.6673\n",
            "Epoch 91/200\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 138.5969 - val_loss: 229.2793\n",
            "Epoch 92/200\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 136.9915 - val_loss: 216.7327\n",
            "Epoch 93/200\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 132.8551 - val_loss: 209.4208\n",
            "Epoch 94/200\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 129.7329 - val_loss: 205.4266\n",
            "Epoch 95/200\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 131.1787 - val_loss: 196.7274\n",
            "Epoch 96/200\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 133.1696 - val_loss: 187.2074\n",
            "Epoch 97/200\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 122.0859 - val_loss: 183.1190\n",
            "Epoch 98/200\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 117.7987 - val_loss: 179.8125\n",
            "Epoch 99/200\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 112.6626 - val_loss: 178.5513\n",
            "Epoch 100/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 112.2959 - val_loss: 174.9427\n",
            "Epoch 101/200\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 105.8937 - val_loss: 177.8274\n",
            "Epoch 102/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 104.3012 - val_loss: 175.3460\n",
            "Epoch 103/200\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 100.5141 - val_loss: 168.4485\n",
            "Epoch 104/200\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 102.2299 - val_loss: 160.7552\n",
            "Epoch 105/200\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 100.0528 - val_loss: 159.1864\n",
            "Epoch 106/200\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 98.5602 - val_loss: 160.6176\n",
            "Epoch 107/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 89.2076 - val_loss: 159.4926\n",
            "Epoch 108/200\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 87.2148 - val_loss: 157.4912\n",
            "Epoch 109/200\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 84.7655 - val_loss: 153.4861\n",
            "Epoch 110/200\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 82.5482 - val_loss: 151.6961\n",
            "Epoch 111/200\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 81.5272 - val_loss: 143.0186\n",
            "Epoch 112/200\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 81.9227 - val_loss: 142.1510\n",
            "Epoch 113/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 78.2665 - val_loss: 149.2989\n",
            "Epoch 114/200\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 71.3099 - val_loss: 145.5337\n",
            "Epoch 115/200\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 69.7915 - val_loss: 137.1711\n",
            "Epoch 116/200\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 67.6924 - val_loss: 132.3969\n",
            "Epoch 117/200\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 64.7355 - val_loss: 128.9878\n",
            "Epoch 118/200\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 62.5298 - val_loss: 125.4081\n",
            "Epoch 119/200\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 63.0887 - val_loss: 123.5110\n",
            "Epoch 120/200\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 58.8181 - val_loss: 122.2562\n",
            "Epoch 121/200\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 55.3760 - val_loss: 125.0315\n",
            "Epoch 122/200\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 54.1714 - val_loss: 115.7290\n",
            "Epoch 123/200\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 52.6499 - val_loss: 102.2505\n",
            "Epoch 124/200\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 50.9658 - val_loss: 99.4262\n",
            "Epoch 125/200\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 46.6497 - val_loss: 102.8888\n",
            "Epoch 126/200\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 45.8441 - val_loss: 114.3654\n",
            "Epoch 127/200\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 48.2328 - val_loss: 115.3741\n",
            "Epoch 128/200\n",
            "3/3 [==============================] - 0s 77ms/step - loss: 44.5492 - val_loss: 105.0224\n",
            "Epoch 129/200\n",
            "3/3 [==============================] - 0s 65ms/step - loss: 40.2444 - val_loss: 97.7921\n",
            "Epoch 130/200\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 42.8640 - val_loss: 96.3975\n",
            "Epoch 131/200\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 39.0695 - val_loss: 100.0307\n",
            "Epoch 132/200\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 35.7789 - val_loss: 102.4384\n",
            "Epoch 133/200\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 36.1779 - val_loss: 93.0573\n",
            "Epoch 134/200\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 32.4755 - val_loss: 85.1874\n",
            "Epoch 135/200\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 36.1619 - val_loss: 81.7587\n",
            "Epoch 136/200\n",
            "3/3 [==============================] - 0s 72ms/step - loss: 30.0721 - val_loss: 86.4820\n",
            "Epoch 137/200\n",
            "3/3 [==============================] - 0s 74ms/step - loss: 36.7726 - val_loss: 91.6320\n",
            "Epoch 138/200\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 28.1599 - val_loss: 88.5823\n",
            "Epoch 139/200\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 31.5794 - val_loss: 84.0439\n",
            "Epoch 140/200\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 28.5968 - val_loss: 79.8701\n",
            "Epoch 141/200\n",
            "3/3 [==============================] - 0s 60ms/step - loss: 27.0410 - val_loss: 83.9854\n",
            "Epoch 142/200\n",
            "3/3 [==============================] - 0s 65ms/step - loss: 25.9241 - val_loss: 85.7623\n",
            "Epoch 143/200\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 23.4334 - val_loss: 81.1090\n",
            "Epoch 144/200\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 26.9746 - val_loss: 75.5787\n",
            "Epoch 145/200\n",
            "3/3 [==============================] - 0s 59ms/step - loss: 22.0931 - val_loss: 76.2012\n",
            "Epoch 146/200\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 24.8764 - val_loss: 75.7961\n",
            "Epoch 147/200\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 20.3954 - val_loss: 77.9050\n",
            "Epoch 148/200\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 20.0627 - val_loss: 76.7078\n",
            "Epoch 149/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 20.8687 - val_loss: 75.4433\n",
            "Epoch 150/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 18.1107 - val_loss: 80.9985\n",
            "Epoch 151/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 16.4842 - val_loss: 83.5309\n",
            "Epoch 152/200\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 18.9081 - val_loss: 77.3680\n",
            "Epoch 153/200\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 14.4559 - val_loss: 68.7411\n",
            "Epoch 154/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 16.1285 - val_loss: 69.4640\n",
            "Epoch 155/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 15.0033 - val_loss: 72.9739\n",
            "Epoch 156/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 18.9432 - val_loss: 78.2685\n",
            "Epoch 157/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 12.9297 - val_loss: 78.3371\n",
            "Epoch 158/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 12.3661 - val_loss: 72.1864\n",
            "Epoch 159/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 11.8869 - val_loss: 65.0499\n",
            "Epoch 160/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 9.5833 - val_loss: 59.1845\n",
            "Epoch 161/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 17.9505 - val_loss: 61.3158\n",
            "Epoch 162/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 10.2359 - val_loss: 67.5082\n",
            "Epoch 163/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 9.3227 - val_loss: 68.9289\n",
            "Epoch 164/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 15.0719 - val_loss: 68.5543\n",
            "Epoch 165/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 9.6820 - val_loss: 66.6813\n",
            "Epoch 166/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 12.1614 - val_loss: 72.3669\n",
            "Epoch 167/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 7.5138 - val_loss: 68.0763\n",
            "Epoch 168/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 9.6778 - val_loss: 63.7828\n",
            "Epoch 169/200\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 7.8135 - val_loss: 70.4181\n",
            "Epoch 170/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 6.3985 - val_loss: 73.9589\n",
            "Epoch 171/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 5.9224 - val_loss: 69.2723\n",
            "Epoch 172/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 8.8402 - val_loss: 66.2685\n",
            "Epoch 173/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 9.2123 - val_loss: 65.1556\n",
            "Epoch 174/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 6.1545 - val_loss: 60.4668\n",
            "Epoch 175/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 12.4883 - val_loss: 54.9207\n",
            "Epoch 176/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 8.5006 - val_loss: 50.0662\n",
            "Epoch 177/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 4.6624 - val_loss: 54.1196\n",
            "Epoch 178/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 8.0034 - val_loss: 62.7247\n",
            "Epoch 179/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 11.1589 - val_loss: 68.9563\n",
            "Epoch 180/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 5.3259 - val_loss: 67.2778\n",
            "Epoch 181/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.7834 - val_loss: 62.0815\n",
            "Epoch 182/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 8.1243 - val_loss: 58.1834\n",
            "Epoch 183/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 5.5811 - val_loss: 62.7569\n",
            "Epoch 184/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 6.2556 - val_loss: 68.5085\n",
            "Epoch 185/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.6669 - val_loss: 64.0971\n",
            "Epoch 186/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 4.8096 - val_loss: 54.9564\n",
            "Epoch 187/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 4.6339 - val_loss: 51.6294\n",
            "Epoch 188/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 4.4220 - val_loss: 51.6863\n",
            "Epoch 189/200\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 3.1837 - val_loss: 53.6646\n",
            "Epoch 190/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.6563 - val_loss: 55.1704\n",
            "Epoch 191/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 4.0024 - val_loss: 53.4626\n",
            "Epoch 192/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.8180 - val_loss: 55.7209\n",
            "Epoch 193/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 6.2375 - val_loss: 55.2988\n",
            "Epoch 194/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.6180 - val_loss: 56.0681\n",
            "Epoch 195/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 7.1375 - val_loss: 56.1962\n",
            "Epoch 196/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.4529 - val_loss: 57.9711\n",
            "Epoch 197/200\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 5.1046 - val_loss: 62.4994\n",
            "Epoch 198/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.1656 - val_loss: 65.9252\n",
            "Epoch 199/200\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 5.4074 - val_loss: 63.8997\n",
            "Epoch 200/200\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 5.6961 - val_loss: 59.8257\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78513043a2f0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "player_2023 = pd.DataFrame({\n",
        "    'Inns' : [9, 9, 7, 9, 9],\n",
        "    'Overs': [79.0, 78.2, 54.3, 81.0, 72.5],\n",
        "    'Mdns': [1, 4, 1, 3, 6],\n",
        "    'Econ': [5.26, 6.70, 6.40, 5.93, 3.65],\n",
        "    'Four_wickets': [3, 1, 1, 0, 1],\n",
        "    'Five_wickets': [0, 1, 0, 1, 0],\n",
        "})\n",
        "\n",
        "player_2023_scaled = sc.transform(player_2023)\n",
        "\n",
        "predicted_wkts_2023 = model.predict(player_2023_scaled)\n",
        "player_2023['Predicted_wkts_2023'] = np.ceil(predicted_wkts_2023)\n",
        "print(player_2023)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOANYqMlQiZC",
        "outputId": "44653adf-386f-4b23-995e-f96eaad2cb51"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 108ms/step\n",
            "   Inns  Overs  Mdns  Econ  Four_wickets  Five_wickets  Predicted_wkts_2023\n",
            "0     9   79.0     1  5.26             3             0                 22.0\n",
            "1     9   78.2     4  6.70             1             1                 21.0\n",
            "2     7   54.3     1  6.40             1             0                 16.0\n",
            "3     9   81.0     3  5.93             0             1                 19.0\n",
            "4     9   72.5     6  3.65             1             0                 18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('scaler.pkl', 'wb') as scaler_file:\n",
        "    pickle.dump(sc, scaler_file)"
      ],
      "metadata": {
        "id": "UTgYH5FdKJ_N"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('wkts_NN_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxRyoH2jwX0A",
        "outputId": "ad3f5321-a076-4262-98f2-01738cb016de"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    }
  ]
}